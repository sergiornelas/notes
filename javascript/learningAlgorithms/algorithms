Qué algoritmo es mejor que el otro?
	- Number of simple operations the computer has to perform {+, -, =...} (YES)

	- Faster (no)
		The problem with time:
			+ Different machines will record different times.
			 +The same machine will record different times.
			+ For fast algorithms, speed measurements may not be precise enough.
	- Less memory-intensive (no)
	- More readable (no)

---------------------------------------------------------------------------------------------------------------------------------------------------------------
BIG O' NOTATION
	- Measure the number of operations that happen.
	- To analyze the performance of an algorithm.
	- Can give us a high level understanding of the time or space complexity of an algorithm.
	- Doesn't care about precision, only about general trends (linear? quadratic? constant?).
	- Depends only on the algorithm, not the hardware used to run the algorithm.
	
TIME COMPLEXITY
	Is a way to formalize fuzzy counting.
	Allows us to talk formally about how the RUNTIME of an ALGORITHM GROWS as the INPUT GROWS.
	When we talk about big O we'r talking about the WORST CASE SCENARIO.

	function addUpTo(n) { return n * (n+1) / 2 }		Always 3 operation -> O(1)	//as n grows, function has the same operations

	function addUpTo(n) {
		let total = 0;
		for (let i = 1; i <= n; i++){							Number of operations is bounded by a multiple of n -> O(n)
			...
		}

	function printAllPairs (n) {
		for (let i = 1; i <= n; i++){
			for (let i = 1; i <= n; i++){						O(n) operation inside of an O(n) operation -> O(n^2)
				...
			}
		}
	
	RULES OF THUMB (THEY ARE CONSQUENCES OF THE DEFINITION OF BIG O NOTATION)
		1) Constants don't matter:	O(2n) -> O(n),	O(500) -> O(1),	O(13n^2) -> O(n^2).
		2) Smaller Terms don't matter: O(n+10) -> O(n),	O(1000n+50) -> O(n),	O(n^2 + 5n + 8) -> O(n^2) (se simplifica).

	BIG O' SHORTHANDS
		These rules WON'T ALWAYS WORK, but are a helpful starting point:
		1) Arithmetic operations are constant.
		2) Variable assignment is constant.
		3) Accessing elements in an array (by index) or object (by key) is constant.
		4) In a loop, the complexity is the length of the loop times the complexity of whatever happens inside of the loop.

---------------------------------------------------------------------------------------------------------------------------------------------------------------
SPACE COMPLEXITY		(auxiliary space complexity).
	How much ADDITIONAL MEMORY do we need to allocate in order to run the code in our algorithm.
	Space required by the ALGORITHM ONLY, NOT INCLUDING SPACE TAKEN UP BY THE INPUTS.
	Just TAKE THE DECLARATIONS (var x = 5;)
	
	RULES OF THUMB
		1) Most primitives (booleans, numbers, undefined, null) are constant space -> (1).
		2) Strings require O(n) space (where n is the string length) -> (n).
		3) Reference types are generally O(n), where n is the length (for arrays) or the number of keys (for objects) -> (n).

		//EXAMPLES:
		function sum(arr) {
			let total = 0;							//one number 		(let total = 0)
			for (let i = 0; i < arr.length; i++){		//another number	(let i = 0)
				total += arr[i];
			}
			return total;
		}
			//O(1) space!	(because primitives It's always the same, no matter the size of the input).
	
		function double(arr) {
			let newArr = [ ];
			for (let i = 0; i < arr.length; i++){
				newArr.push(2 * arr[ i ]);			//n numbers ( arr[ i ] )
			}
			return newArr
		}
			//O(n) space! (because the new array space depends on n, the value it's not the same).

---------------------------------------------------------------------------------------------------------------------------------------------------------------
LOGARITHMS
	The logarithm of a number roughly measures the number of times you can divide that number by 2 before you get a value that's
	less than or equal to one.

	8 / 2 = 4		25 / 2 = 12.5
	4 / 2 = 2		12.5 / 2 = 6.25
	2 / 2 = 1		6.25 / 2 = 3.125
	log(8) = 3 		3.125 / 2 = 1.5625
					1.5625 / 2 = 0.78125	//result will be some number  between four and five
					log(25) = 4.64

	Inverse of exponentiation:	log¨2¨(8) = 3	->	2^3 = 8
	log === log¨2¨
	
	USES:
	- Sometimes Big O' expressions involve more complex mathematical expressions.
	- Efficient sorting algorithms involve logarithms.
	- Recursion sometimes involves logarithmic space complexity.

---------------------------------------------------------------------------------------------------------------------------------------------------------------
PERFORMANCE OF ARRAYS AND OBJECTS
	OBJECTS (are fast at pretty much everything, things just float around in a gelatinous mass)
		WHEN TO USE OBJECTS
			+ When you don't need order.
			+ When you need fast access / insertion and removal.
		
		BIG O' OF OBJECTS
			Insertion - O(1)
			Removal - O(1)
			Searching - O(N)	//Checking to see if a given piece of information is in value somewhere.
			Access - O(1)

		BIG O' OF OBJECTS METHODS
			Object.keys - O(N)
			Object.values - O(N)
			Object.entries - O(N)
			hasOwnProperty - O(1)

	ARRAYS (ordered lists)
		Add and remove from the end and avoid adding and removing from the beginning because that starts cascade effect.
		WHEN TO USE ARRAYS
			+ When you need order.
			+ When you need fast access / insertion and removal (sort of...)
			
		BIG O' OF ARRAYS
			Insertion - It depends... If you insert the element at the beginning of the array, all the elements are going to move to next 
						field.
			Removal - It depends... The same concept as insertion.
			Searching - O(N)
				indexOf()  For finding the index of a value we need to loop though the array to get a match.
			Access - O(1)

		BIG O' OF ARRAY OPERATIONS
			push - O(1)
			pop - O(1)
			shift - O(N)
			unshift - O(N)
			concat - O(N)
			splice - O(N)
			sort - O(N * log N)	//very slow
			forEach/map/filter/reduce/etc - O(N)

---------------------------------------------------------------------------------------------------------------------------------------------------------------
ALGORITHMS
	Set of steps to accomplish a certain task.

	HOW DO YOU IMPROVE?
		1) Devise a plan for solving problems (Diseña un plan para resolver problemas)
		2) Master common problem solving patterns

	PROBLEM SOLVING APPROACH
		1) Understand the Problem
			1) Can I restate the problem in my own words?
			2) What are the inputs that go into the problem?
			3) What are the outputs that should come from the solution to the problem?
			4) Can the outputs be determined from the inputs? In other words, do I have enough information to solve the problem?
			      (You may not be able to answer this question until you set about solving the problem. That's okay; it's still worth
			      considering the question at this early stage).
			5) How should I label the important pieces of data that are a part of the problem?

		2) Explore Concrete Examples (example inputs that are in the instructions)
			- Coming up with examples can help you understand the problem better.
			- Examples also provide sanity checks that your eventual solution works how it should.

		3) Break it Down (steps, similar to pseudocode)
			Explicitly write out the steps you need to take. This forces you to think about the code you'll write before
			you write it, and helps you catch any lingering conceptual issues or misunderstanding before you dive in
			and have to worry about details as well.

			Esto aplica para ENTREVISTAS. Ellos no quieren que escribas código en silencio, quieren que sepas comunicar qué estas
			haciendo.

		4) Solve/Simplify
			Solve the problem, if you can't... solve a simpler problem! Try to ignore the part that is giving you a really hard time in order to 
			focus on everything else. En una ENTREVISTA en lugar de quedarte trabado y no hacer progreso por poner "todos los huevos en 
			un solo canasto", se ve mal. Es mejor empezar a escribir código a las cosas que sabes como hacerlas.

			1) Find the core difficulty in what you're trying to do
			2) Temporarily ignore that difficulty
			3) Write a simplified solution
			4) Then incorporate that difficulty back in.
			
		5) Look Back and Refactor
			Los ENTREVISTADORES te preguntan: ¿Puedes mejorar el rendimiento de tu algoritmo? (time/space complexity)
			Restructure (the source code of an application or piece of software) so as to improve operation without altering functionality.

---------------------------------------------------------------------------------------------------------------------------------------------------------------
PROBLEM SOLVING PATTERNS
	Archetypes, blueprints that may come in handy.

	FREQUENCY COUNTER PATTERN 									       (let obj1 = {}; let obj2 = {}; for (let val of arr1) {...} for (let val of arr2) {...})
		This can often AVOID THE NEED FOR NESTED LOOPS or O(N^2) operations with arrays / strings.
		This pattern USES OBJECTS or sets to collect values/frequencies of values

		TWO LOOPS it's WAY BETTER than TWO NESTED LOOPS.

	MULTIPLE POINTERS 			   										 														 ([-3, -2, -1, 0, 1, 2, 3])
		Creating pointers of values that correspond to an index or position and move towards the beggining, end or middle based
		on a certain condition.
		Very efficient for solving problemns with minimal space complexity as well.

		//Caso [ i, j...] (for)
		//Enviar true si existen elementos duplicados en el arreglo
		[1, 4, 3, 2, 5, 4]
		//En lugar de comparar un elemento con cada uno de los elementos de un arreglo
			[1=4 ? no], [1=3 ? no], [1=2 ? no] ... [4=3 ? no], [4=2 ? no] ... 						(for loop { for loop })
		//Ordenas el arreglo en orden ascendente
		➡️ arreglo.sort((a,b) => a > b);
			[1, 4, 3, 2, 5, 4]   ->   [1, 2, 3, 4, 4, 5]
		//Ahora comparas el primer elemento con el segundo elemento, y así llevartela de par en par...
			[1=2 ? no], [2=3 ? no], [3=4 ? no], [4=4 ? si] 										(for loop { if condition })

		//Caso [ i, ... j]	(while)
		//Enviar true si existen dos elementos que su suma es igual a 0
		[-3, -2, -1, 0, 1, 4, 5]
		//En lugar de sumar elemento con cada uno de los elementos del arreglo
			[-3+(-2) = 0 ? no], [-3+(-1) = 0 ? no] ... [-2+(-1) = 0 ? no]... 						(for loop { for loop })
		//Ahora sumas el primer elemento con el último elemento, aumentando el primer indice si el resultado:
		//es < 0 o aumentar el ultimo indice si el resultado es > 0.
			[-3+5 = 0 ? no] [2 > 0 ? j--] || [2 < 0 ? i++]											(while loop { if condition } { elif condition })
	
	SLIDING WINDOW																										          (hellothere -> [lother])
		This pattern involves creating a window which can either be an array or number from one position to another.
		Depending on a certain condition, the window either increases or closes (and a new window is created).
		Very useful for keeping track of a subset of data in an array/string etc.

		//Encontrar la máxima suma de 3 números CONSECUTIVOS del arreglo.
		[2,6,9,4,8,5,7,3]
		//En lugar de sumar de 3 en 3 (repitiendo la suma de los primeros dos num.) hasta almacenar el número más grande en una variable:
			[2+6+9], [6+9+4],[9+4+8] ...														(for loop { for loop })
		//Simplemente del primer total creado RESTAS el primer número y SUMAS el siguiente número:
			[2+6+9], //17																		(primer for loop)
			[-2+17+4] //19, [-6+19+8] //21, [-9+21+5] //17, [-4+17-7] //6, [-8+6-3] // -5	(segundo for loop)
			<< El máximo número es 21
	
	DIVIDE AND CONQUER	(It's actually the name of the pattern)											         ([ _ _ _ _ | x x x x ] -> [ _ _ _ _ _ _ | x x ]
		This pattern involves dividing a data set into smaller chunks and then repeating a process with a subset of data.
		This pattern can tremendously decrease time complexity.

		//Encontrar el index [i] de un arreglo donde se encuentra el número 15.
		[1,2,3,5,6,8,9,12,15,16,29]
		//En lugar de hacer un simple for loop donde comparamos cada elemento del arreglo con el número específico:
			if (arr[i] === 15) {return i }
		//Toma el elemento de ENMEDIO (8)  y comparar si 8 es más grande que 15 o más chico que 15.
			//(porque el arreglo esta ordenado numéricamente esto funcionará),
		// 15 es más grande que 8, entonces todos los números anteriores y el 8 se ignorarán.
		[x,x,x,x,x,x,9,12,15,16,29]

---------------------------------------------------------------------------------------------------------------------------------------------------------------
RECURSION
	A process (function) that calls itself.
	It's EVERYWHERE!:
		- JSON.parse / JSON.stringify.
		- document.getElementById and DOM traversal algorithms.
		- Object traversal.		
	It's sometimes a cleaner alternative to iteration.

THE CALL STACK	//apilar
	Any time a function is invoked it is placed (pushed) on the top of the call stack.
	When JavaScript sees the return keyword or when the function ends, the compiler will remove (pop).

	Why do I care?
		- You're used to functions being pushed on the call stack and popped off when they are done.
		- When we write recursive functions, we keep pushing new functions onto the call stack!

